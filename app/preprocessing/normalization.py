import re
import unicodedata
from typing import List

from preprocessing.ocr import get_plain_text

# Headers and Footer
RE_HEADER_FOOTER = [
    re.compile(r'^\s*INSTITUTO\s*$', re.I),
    re.compile(r'^\s*SUPERIOR\s*$', re.I),
    re.compile(r'^\s*STH?\s*TECNOLOGICO\s*$', re.I),
    re.compile(r'^\s*ST\s*TECNOLOGICO\s*$', re.I),
    re.compile(r'^\s*TECNOLOGICO\s*$', re.I),
    re.compile(r'^\s*YARUQUI\s*$', re.I),
    re.compile(r'^\s*Version\s*:\s*\d+\s*$', re.I),
    # Contact Data
    re.compile(r'^\s*\(?\+?\d[\d\-\s\(\)]{6,}\s*$', re.I), 
    re.compile(r'^\s*(www\.[^\s]+|https?://[^\s]+)\s*$', re.I),
    re.compile(r'^\s*[\w\.-]+@[\w\.-]+\.\w+\s*$', re.I), 
    re.compile(r'^\s*calle\s+.+$', re.I), 
]

# Previous resolution mention
RE_PREVIOUS_RES = re.compile(r'^\s*RESOLUCI[ÓO]N\s*:?\s*RCP.*2022.*$', re.I)

# Keep actual resolution
RE_RES_2025 = re.compile(r'RESOLUCI[ÓO]N.*2025', re.I)

# Sections and articles initializers
RE_SECTION_HEADERS = [
    re.compile(r'^\s*CONSIDERANDO\s*:?\s*$', re.I),
    re.compile(r'^\s*RESUELVE\s*:?\s*$', re.I),
    re.compile(r'^\s*DISPOSICIONES\s+FINALES\s*$', re.I),
]

# To keep artícles
RE_ARTICLES = re.compile(
    r'^\s*(?:Art[íi]?culo|Art\.)\s*'
    r'(?:\d+|PRIMERO|SEGUNDO|TERCERO|CUARTO|QUINTO|SEXTO|S[EÉ]PTIMO|OCTAVO|NOVENO|D[EÉ]CIMO)'
    r'\s*[\.\-–—]+',
    re.I
)

# Inline article header
ARTICLE_HEADER_INLINE_RX = re.compile(
    r'\s+(?=(?:Art[íi]?culo|Art\.)\s*'
    r'(?:\d+|PRIMERO|SEGUNDO|TERCERO|CUARTO|QUINTO|SEXTO|S[EÉ]PTIMO|OCTAVO|NOVENO|D[EÉ]CIMO)'
    r'\s*[\.\-–—]+)',
    re.I
)

# Final provisions
RE_FINAL_PROVISIONS = re.compile(
    r'^\s*(PRIMERA|SEGUNDA|TERCERA|CUARTA|QUINTA|SEXTA|S[EÉ]PTIMA|OCTAVA|NOVENA|D[EÉ]CIMA)\s*[\.\-–—]*\s*',
    re.I
)

# Ensure space after "Artículo N.-" / "Art. N.-"
SPACE_AFTER_DOT_DASH_RX = re.compile(
    r'((?:Art[íi]?culo|Art\.)\s*'
    r'(?:\d+|PRIMERO|SEGUNDO|TERCERO|CUARTO|QUINTO|SEXTO|S[EÉ]PTIMO|OCTAVO|NOVENO|D[EÉ]CIMO)'
    r'\s*[\.\-–—]+)(\S)',
    re.I
)

# To fix docTR gramatical errors
OCR_COMMON_FIXES: List[tuple[re.Pattern, str]] = [
    (re.compile(r'\bano(s?)\b', re.I), r'año\1'),
    (re.compile(r'\bArticulo\b', re.I), 'Artículo'),
    (re.compile(r'\bConstitucion\b', re.I), 'Constitución'),
    (re.compile(r'\bRepublica\b', re.I), 'República'),
    (re.compile(r'\bEducacion\b', re.I), 'Educación'),
    (re.compile(r'\btecnologico\b', re.I), 'tecnológico'),
    (re.compile(r'\bTecnologico\b', re.I), 'Tecnológico'),
    (re.compile(r'car[âa]cter', re.I), 'carácter'),
]

# Final message detector
RE_FINAL_MESSAGE = re.compile(r'\bDado en\b', re.I)

# Punctuation fixes
PUNCT_SWAPS = [
    ('“', '"'), ('”', '"'), ('„', '"'), ('«', '"'), ('»', '"'),
    ("’", "'"), ("‘", "'"),
    ('—', '-'), ('–', '-'), ('-', '-'), 
]

# Normalize punctuation
def _normalize_unicode(text: str) -> str:
    text = unicodedata.normalize('NFC', text)
    for src, dst in PUNCT_SWAPS:
        text = text.replace(src, dst)
    return text

def _strip_headers_and_footers(text: str) -> str:
    """
        Remove repeating header/footer and contact lines. 
        Keep actual resolution header.
    """
    out_lines: List[str] = []
    for raw in text.splitlines():
        line = raw.strip()
        if not line:
            continue

        # Remove previous resolution from 2022
        if RE_PREVIOUS_RES.search(line):
            continue

        # Remove generic header/footer/contact filters
        if any(rx.search(line) for rx in RE_HEADER_FOOTER):
            continue

        # Remove short, all-caps "staple" words typical from scanned headers
        if (
            line.isupper()
            and len(line) <= 30
            and not any(hx.search(line) for hx in RE_SECTION_HEADERS)
            and not RE_RES_2025.search(line)  # Remove current resolution header
        ):
            tokens = {
                'INSTITUTO', 'SUPERIOR', 'TECNOLOGICO', 'YARUQUI', 'RECTORADO',
                'ISTY', 'SUPTRITO', 'FACNOLSOICO'
            }
            if line.replace('.', '').replace('-', '').strip() in tokens:
                continue

        out_lines.append(line)

    return "\n".join(out_lines)

# Clean words separated by line break
def _dehyphenate(text: str) -> str:
    # joins words broken by a hyphen
    text = re.sub(r'(\w)-\n(\w)', r'\1\2', text)
    # clean possible hyphens generated by docTR ocr
    text = re.sub(r'(\w)-\s+(\w)', r'\1- \2', text)
    return text

def _apply_ocr_common_fixes(text: str) -> str:
    for rx, repl in OCR_COMMON_FIXES:
        text = rx.sub(repl, text)
    return text

# Clean multiple spaces
def _compact_whitespace(text: str) -> str:
    text = re.sub(r'[ \t]+', ' ', text)
    text = re.sub(r'\u00A0', ' ', text) 
    text = re.sub(r'\n{2,}', '\n', text)
    return text.strip()


def _protect_markers(text: str) -> str:
    lines = text.splitlines()
    out: List[str] = []

    for line in lines:
        l = line.strip()
        if not l:
            continue

        # Section Headers
        if any(rx.match(l) for rx in RE_SECTION_HEADERS):
            out.append('<<BR>>' + l + '<<BR>>')
            continue

        # Articles
        if RE_ARTICLES.match(l):
            out.append('<<BR>>' + l)
            continue

        # Final Provisions
        if RE_FINAL_PROVISIONS.match(l):
            out.append('<<BR>>' + l)
            continue

        out.append(l)

    return "\n".join(out)


def _merge_paragraphs(text: str) -> str:
    """
    Merge lines into paragraphs while preserving:
    - Section headers
    - True article headers (RESUELVE): 'Artículo N.-' / 'Art. N.-'
    - Final provisions (ordinals)
    Also enforce breaks before 'Que,' (recitals) and 'Dado en...' (final message).
    """
    t = text

    # Replace single newlines with spaces (we will re-introduce breaks via markers)
    t = t.replace('\n', ' ')
    # Restore markers as paragraph breaks
    t = t.replace('<<BR>>', '\n\n')

    # Break before "Que," (recitals)
    t = re.sub(r'\s+(Que,)', r'\n\1', t)

    # Break before any inline true article header (prevents breaking 'Artículo 350...' in CONSIDERANDO)
    t = ARTICLE_HEADER_INLINE_RX.sub('\n', t)

    # Ensure a space after "Artículo N.-"/"Art. N.-" when OCR glued next char
    t = SPACE_AFTER_DOT_DASH_RX.sub(r'\1 \2', t)

    # Break before final provisions ordinals if glued
    t = re.sub(
        r'\s+(PRIMERA|SEGUNDA|TERCERA|CUARTA|QUINTA|SEXTA|S[EÉ]PTIMA|OCTAVA|NOVENA|D[EÉ]CIMA)\s*[\.\-–—]*',
        r'\n\1. ', t, flags=re.I
    )

    # Break before the final message ("Dado en ...")
    t = re.sub(r'\s+(Dado en\b)', r'\n\1', t, flags=re.I)

    # Compact spaces and excessive newlines
    t = re.sub(r'[ \t]+', ' ', t)
    t = re.sub(r'\n{3,}', '\n\n', t)

    # Beautify canonical section headers
    t = re.sub(r'\n+(CONSIDERANDO\s*:?)', r'\n\n\1', t, flags=re.I)
    t = re.sub(r'\n+(RESUELVE\s*:?)', r'\n\n\1', t, flags=re.I)
    t = re.sub(r'\n+(DISPOSICIONES\s+FINALES)', r'\n\n\1', t, flags=re.I)

    return t.strip()

def _cleanup_inline_noise(text: str) -> str:
    """
    Remove known inline noise tokens that slipped through after reflow.
    """
    noise_tokens = [
        r'ISTY', r'SUPTRITO', r'FACNOLSOICO', r'Coccee'
    ]
    # Remove tokens as whole words anywhere in the text
    for tok in noise_tokens:
        text = re.sub(rf'\b{tok}\b', '', text)

    # Remove extra spaces created by deletions
    text = re.sub(r'\s{2,}', ' ', text)
    text = re.sub(r' \.', '.', text)
    text = re.sub(r'\n[ \t]+', '\n', text)

    return text.strip()


def get_clean_text() -> str:
    """
        Run the full normalization pipeline on OCR output and return a clean text
        with clear sections and real article headers preserved for the extraction layer.
    """
    raw = get_plain_text()

    # 1) Unicode + punctuation normalization
    t = _normalize_unicode(raw)

    # 2) Strip headers/footers/contact lines and previous (2022) resolution
    t = _strip_headers_and_footers(t)

    # 3) De-hyphenate broken words across lines
    t = _dehyphenate(t)

    # 4) Minimal OCR spelling fixes
    t = _apply_ocr_common_fixes(t)

    # 5) Compact whitespace/newlines before reflow
    t = _compact_whitespace(t)

    # 6) Protect section/article headers with markers
    t = _protect_markers(t)

    # 7) Reflow paragraphs and enforce breaks in key places
    t = _merge_paragraphs(t)
    
    # 8) Final inline noise cleanup
    t = _cleanup_inline_noise(t)

    # Separate resolution from resolution title
    t = re.sub(
        r'(RESOLUCI[ÓO]N:[^\n]+?)\s+(EL\s+ORGANO\s+COLEGIADO\s+SUPERIOR\b)',
        r'\1\n\2',
        t, flags=re.I
    )

    return t
